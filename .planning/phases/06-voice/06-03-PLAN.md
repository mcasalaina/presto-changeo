---
phase: 06-voice
plan: 03
type: execute
wave: 2
depends_on: ["06-01", "06-02"]
files_modified:
  - frontend/src/components/VoiceToggle.tsx
  - frontend/src/App.tsx
  - frontend/src/App.css
autonomous: false

must_haves:
  truths:
    - "User can see voice toggle button"
    - "User can enable voice mode with one click"
    - "User can see mute button when voice is enabled"
    - "User can see visual indicator when listening/speaking"
    - "Charts appear when AI mentions them in voice"
  artifacts:
    - path: "frontend/src/components/VoiceToggle.tsx"
      provides: "Voice toggle UI with mute and indicators"
      min_lines: 50
    - path: "frontend/src/App.tsx"
      provides: "Voice integration in main app"
      contains: "useVoice"
  key_links:
    - from: "VoiceToggle.tsx"
      to: "useVoice hook"
      via: "props from parent"
      pattern: "isEnabled.*isMuted.*isListening"
    - from: "App.tsx"
      to: "VoiceToggle"
      via: "component render"
      pattern: "<VoiceToggle"
---

<objective>
Create voice UI components and integrate into the main application.

Purpose: Provide the user-facing voice controls - a toggle button to enable/disable voice mode, a mute button to prevent feedback, and visual indicators showing listening/speaking states. Wire up tool results from voice to display charts.

Output: `frontend/src/components/VoiceToggle.tsx` component, updated `frontend/src/App.tsx` with voice integration.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
@~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-voice/06-CONTEXT.md

# Must reference prior plan summaries for context integration
@.planning/phases/06-voice/06-01-SUMMARY.md
@.planning/phases/06-voice/06-02-SUMMARY.md

# App and styling context
@frontend/src/App.tsx
@frontend/src/App.css
@frontend/src/components/PersonaCard.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create VoiceToggle component</name>
  <files>frontend/src/components/VoiceToggle.tsx</files>
  <action>
Create `frontend/src/components/VoiceToggle.tsx` - the voice control UI.

**Component props:**
```typescript
interface VoiceToggleProps {
  isEnabled: boolean
  isMuted: boolean
  isListening: boolean
  isSpeaking: boolean
  status: 'disconnected' | 'connecting' | 'connected' | 'error'
  onEnable: () => void
  onDisable: () => void
  onToggleMute: () => void
}
```

**Visual design (from 06-CONTEXT.md):**
- Minimal visual indicator - subtle pulse or waveform, nothing distracting
- Mute button visible when voice enabled
- Show listening/speaking state

**Implementation:**

1. **Main toggle button:**
   - When disabled: microphone icon, "Enable Voice" tooltip
   - When enabled: shows active state with pulse animation
   - Shows connecting spinner when status = "connecting"
   - Shows error state (red) when status = "error"

2. **Mute button:**
   - Only visible when voice is enabled
   - Mic icon when unmuted, mic-off icon when muted
   - Clear visual difference between muted/unmuted states

3. **Status indicator:**
   - Small pulse animation when isListening (user speaking)
   - Different pulse when isSpeaking (AI speaking)
   - Use CSS animations for smoothness

**Layout:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üé§ [Voice] [üîá] ‚îÇ  <- Main toggle + mute button (when enabled)
‚îÇ   ‚óØ listening   ‚îÇ  <- Status indicator (subtle)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**CSS classes to add (will be in App.css):**
- `.voice-toggle` - container
- `.voice-button` - main toggle
- `.voice-button.active` - when enabled
- `.voice-button.listening` - pulse when user speaking
- `.voice-button.speaking` - different pulse when AI speaking
- `.mute-button` - mute toggle
- `.mute-button.muted` - when muted
- `.voice-status` - status indicator text

**Icons:** Use Unicode emoji for simplicity: üé§ (mic), üîá (muted), or simple SVG inline.
  </action>
  <verify>
    - TypeScript compiles: `cd frontend && npx tsc --noEmit`
    - Component exports correctly
  </verify>
  <done>
    - VoiceToggle.tsx exists with enable/disable/mute controls
    - Shows listening/speaking visual indicators
    - Clean, minimal design per CONTEXT.md
  </done>
</task>

<task type="auto">
  <name>Task 2: Add VoiceToggle styles to App.css</name>
  <files>frontend/src/App.css</files>
  <action>
Add CSS styles for VoiceToggle component.

**Styles to add:**

```css
/* Voice Toggle */
.voice-toggle {
  display: flex;
  align-items: center;
  gap: 8px;
}

.voice-button {
  display: flex;
  align-items: center;
  justify-content: center;
  width: 40px;
  height: 40px;
  border-radius: 50%;
  border: 2px solid var(--color-text-muted);
  background: var(--color-surface);
  color: var(--color-text);
  cursor: pointer;
  transition: all 0.2s ease;
}

.voice-button:hover {
  border-color: var(--color-primary);
  background: var(--color-primary-hover);
}

.voice-button.active {
  border-color: var(--color-primary);
  background: var(--color-primary);
  color: white;
}

.voice-button.connecting {
  opacity: 0.7;
  cursor: wait;
}

.voice-button.error {
  border-color: #ef4444;
  background: #fee2e2;
  color: #ef4444;
}

/* Listening animation - subtle pulse */
.voice-button.listening {
  animation: voice-pulse 1.5s ease-in-out infinite;
}

@keyframes voice-pulse {
  0%, 100% { box-shadow: 0 0 0 0 rgba(var(--color-primary-rgb), 0.4); }
  50% { box-shadow: 0 0 0 8px rgba(var(--color-primary-rgb), 0); }
}

/* Speaking animation - different rhythm */
.voice-button.speaking {
  animation: voice-speak 0.8s ease-in-out infinite;
}

@keyframes voice-speak {
  0%, 100% { transform: scale(1); }
  50% { transform: scale(1.05); }
}

/* Mute button */
.mute-button {
  display: flex;
  align-items: center;
  justify-content: center;
  width: 32px;
  height: 32px;
  border-radius: 50%;
  border: 1px solid var(--color-text-muted);
  background: transparent;
  color: var(--color-text-muted);
  cursor: pointer;
  transition: all 0.2s ease;
}

.mute-button:hover {
  border-color: var(--color-text);
  color: var(--color-text);
}

.mute-button.muted {
  background: #fee2e2;
  border-color: #ef4444;
  color: #ef4444;
}

/* Voice status indicator */
.voice-status {
  font-size: 0.75rem;
  color: var(--color-text-muted);
  margin-left: 4px;
}
```

**Note:** Use CSS custom properties (already defined in App.css from mode system) for theming consistency.

**Add RGB version of primary color if not present:**
```css
:root {
  --color-primary-rgb: 34, 197, 94; /* Will be overridden by mode */
}
```
  </action>
  <verify>
    - CSS is valid (no syntax errors)
    - Styles use existing custom properties
  </verify>
  <done>
    - Voice toggle styles added to App.css
    - Pulse animations for listening/speaking
    - Mute button styling
  </done>
</task>

<task type="auto">
  <name>Task 3: Integrate voice into App.tsx</name>
  <files>frontend/src/App.tsx</files>
  <action>
Integrate useVoice hook and VoiceToggle component into App.tsx.

**Changes:**

1. **Import hook and component:**
   ```typescript
   import { useVoice } from './hooks/useVoice'
   import { VoiceToggle } from './components/VoiceToggle'
   ```

2. **Use the hook in AppContent:**
   ```typescript
   const {
     isEnabled: voiceEnabled,
     isMuted: voiceMuted,
     isListening,
     isSpeaking,
     status: voiceStatus,
     enable: enableVoice,
     disable: disableVoice,
     toggleMute: toggleVoiceMute
   } = useVoice({
     onTranscript: (role, text) => {
       // Add transcript as chat message for display
       if (text.trim()) {
         setMessages(prev => [...prev, {
           id: Date.now().toString(),
           role,
           content: text,
           timestamp: new Date()
         }])
       }
     },
     onToolResult: (tool, result) => {
       // Reuse existing tool result handling (chart rendering)
       if (tool === 'show_chart') {
         const chartResult = result as {
           chart_type: 'line' | 'bar' | 'pie' | 'area'
           title: string
           data: Array<{ label: string; value: number }>
         }
         setVisualization(
           <ChartRenderer
             chartType={chartResult.chart_type}
             title={chartResult.title}
             data={chartResult.data}
           />
         )
       } else if (tool === 'show_metrics') {
         const metricsResult = result as {
           metrics: Array<{ label: string; value: string | number; unit?: string }>
         }
         setDashboardMetrics(metricsResult.metrics)
       }
     },
     onError: (error) => {
       console.error('Voice error:', error)
     }
   })
   ```

3. **Add VoiceToggle to chat header:**
   Place next to the status dot in the chat header:
   ```tsx
   <header className="chat-header">
     <span className="header-title">Chat Assistant</span>
     <div className="header-actions">
       <VoiceToggle
         isEnabled={voiceEnabled}
         isMuted={voiceMuted}
         isListening={isListening}
         isSpeaking={isSpeaking}
         status={voiceStatus}
         onEnable={enableVoice}
         onDisable={disableVoice}
         onToggleMute={toggleVoiceMute}
       />
       <button className="new-chat-button" onClick={handleNewChat} title="New Chat">
         +
       </button>
       <span className="status-dot" style={{ backgroundColor: getStatusColor(status) }} />
     </div>
   </header>
   ```

4. **Disable text input when voice is enabled:**
   ```tsx
   <input
     type="text"
     className="chat-input"
     placeholder={voiceEnabled ? "Voice mode active - speak to chat" : "Chat with me here..."}
     value={inputValue}
     onChange={(e) => setInputValue(e.target.value)}
     onKeyDown={handleKeyPress}
     disabled={status !== 'connected' || voiceEnabled}
   />
   ```

**Note:** Tool results from voice use same handlers as text chat, so charts/metrics appear consistently.
  </action>
  <verify>
    - `cd frontend && npx tsc --noEmit` passes
    - `cd frontend && npm run build` passes
  </verify>
  <done>
    - useVoice hook integrated in AppContent
    - VoiceToggle rendered in chat header
    - Tool results from voice render charts
    - Text input disabled during voice mode
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Voice toggle UI with microphone capture, audio playback, and visual indicators</what-built>
  <how-to-verify>
    1. Start backend: `cd backend && venv\Scripts\activate && python main.py`
    2. Start frontend: `cd frontend && npm run dev`
    3. Visit: http://localhost:5173

    **Test voice toggle:**
    4. Click the microphone button in chat header
    5. Browser should request microphone permission - allow it
    6. Button should show "active" state with pulse animation
    7. Speak something - listening indicator should pulse
    8. AI should respond with voice AND the response should appear in chat
    9. Click mute button - icon should change, speaking shouldn't trigger AI

    **Test voice-visual sync:**
    10. With voice enabled, say "Show me a pie chart of my spending"
    11. AI voice should respond AND chart should appear in dashboard

    **Test disable:**
    12. Click voice button again to disable
    13. Text input should re-enable
  </how-to-verify>
  <resume-signal>Type "approved" if voice works end-to-end, or describe issues</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `cd frontend && npm run build` succeeds
- [ ] VoiceToggle component renders in chat header
- [ ] Voice can be enabled/disabled
- [ ] Mute button works
- [ ] Transcripts appear in chat
- [ ] Tool results render charts
- [ ] Human verification passed
</verification>

<success_criteria>
- All tasks completed
- User approved voice functionality via checkpoint
- VoiceToggle shows enable/disable/mute controls
- Visual indicators for listening/speaking states
- Voice transcripts appear in chat messages
- Charts appear when AI mentions them via voice
</success_criteria>

<output>
After completion, create `.planning/phases/06-voice/06-03-SUMMARY.md`
</output>
