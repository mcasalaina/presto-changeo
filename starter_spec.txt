A demo website called Presto-Change-O that simulates fully interactive AI-driven interfaces across a range of industries. It should have a layout like in ".\layout_prototype.png", with a chatbot area on the left hand side, a voicebot option, and a central, interactive area. It should be in light mode. This layout changes its function according to the mode it's in. If I say "Presto-Change-O, you're a bank" then the entire interface should change itself to be a bank. It should still have the same layout, with the chatbot area, voicebot, and interactive center - but it should now act as a bank and should simulate the answers to banking questions very faithfully.

The central interactive area should show graphs and functions pertaining to the mode it's in. If it's in bank mode, those should be graphs for your checking and savings accounts, and a burndown chart of your mortgage. If it's in insurance mode, it should show graphs for your life insurance and car insurance. If it's in healthcare mode, it should show graphs about healthcare coverage and usage. Changing the mode should change the coloring of the page, mimicking the colors of major players in that industry (for example, banking mode might mimic the colors of Wells Fargo, healthcare mode might mimic the colors of Kaiser Permanente, but it should not match those colors exactly - you can use Playwright to look at their pages if needed to get some examples). This central pane should be activated by the chatbot and voicebot - for example, if I'm in bank mode, I should say "how much is left in my checking account?" and that should cause it to make a tool call which shows the checking account chart. None of this should be deterministic or heuristic - it should be driven by a LLM, and that LLM should interpret 

You'll be using Microsoft Foundry in Azure. Use the Microsoft docs MCP to look up any information needed for this. The project aipmaker-project at https://aipmaker-project-resource.services.ai.azure.com/api/projects/aipmaker-project has many models you can use to populate this. Use the model-router deployment as the core LLM for this. Use gpt-image-1-mini to generate images like graphs. Use gpt-realtime for voice. All of these are already defined in this project - use az to inspect it if you need any more information about it. Use Foundry agents if needed, particularly making one including Grounding with Bing in case it needs to do a web search. Cache any styles and images produced so they can be reused later. Use managed identity and InteractiveBrowserCredential for the user to log in. Make a .env file containing the properties needed, and load from that .env file at startup instead of reading it from the system environment vars. Add .env to .gitignore and never stage or commit it. Make a venv or uv in this directory and make a requirements.txt that contains all that is needed for this project, and install that requirements.txt to the venv. Be sure to add any venv or uv files to the .gitignore too.

Once you've built the interface, test it via Playwright through its chatbot to verify that it works as expected.